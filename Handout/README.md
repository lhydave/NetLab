## Video Quality Metrics

这一部分我们着眼于视频质量的三个通用评价指标，即卡顿 (freezing)、模糊 (blur) 和噪声 (noise)。关于音画同步的相关介绍，请参考`synchronization.zip`内的相关文件。

请注意，我们在此采用的评价方法都是无参考 (No Reference, NR) 的，即只根据目标视频本身进行评价，而不需要“原始视频”或“参考视频”；因为在在线会议场景下，所谓的“原始视频”在用户端是不可获得的。

`metrics.py`提供了一个样例代码实现，把它作为你工作的开始。

### Introduction to these metrics

#### Freezing

Freezing直观表现为视频前后两帧的内容相同，因此可以简单地通过相邻帧差的绝对值大小来检测freezing的帧。在此过程中至少有以下问题需要考虑：由于网络传输、视频压缩等因素，freezing的前后两帧之间可能会存在微小的差异，因此判断是否freezing的阈值不能简单设为0；视频中的某些场景可能相对比较静止，需要把这些帧和freezing区别开……`ref.pdf`第2章描述了一个检测的算法，样例代码中的`freeze_detect`是它的一个实现。

#### Blur

我们对每帧图像采用基于FFT的方法来检测blur。相比基于拉普拉斯算子或其他更复杂的算法，FFT方法实现较为简单，且复杂度较低（这对于会议视频评估非常重要，因为我们需要相对实时的指标来实现视频质量的调整和自适应）。样例代码中的`blur_level`提供了基于FFT的算法实现。

#### Noise

和blur不同，基于单帧图像的noise计算复杂度相对较高（当然也许我们的工作做得不够完善，如果你有更好的算法，请别犹豫把它写进你的报告里），因此我们采用了一个妥协的方法。设每帧图像中的噪声都服从均值为0、标准差为$\sigma$的正态分布（这在连续的一小段中是成立的），则两帧之差的噪声为一均值为0、标准差为$\sqrt{2}\sigma$的正态分布，因此帧差的噪声可以反映单帧的噪声水平。如果前后两帧图像完全相同，则帧差中只包含噪声；然而实际情况中由于人或物体的运动，帧差中还包含运动造成的差异，因此需要将这部分排除在外。样例代码中的`noise_level`是这个思路的一个简单实现。

### What you need to do

#### Basic

- 参考样例代码，在所有采集的视频数据上获取三个metric的数值；
- 以200帧为区间，计算每个区间内blur和noise的均值、freezing的帧数，并通过折线图等方式可视化结果；
- 根据结果并结合音画同步指标和Wireshark数据，对比总结不同会议软件/不同网络环境……场景下的性能。

#### Bonus

- 结合你的所学知识，尝试分析不同会议软件/不同网络环境……场景下的性能差异的原因。
- 视频卡顿可分为两种，分别为dropped frames（如为了节约网络带宽，发送端决定每两帧丢弃一帧）和repeated frames（通常是由于丢包等因素下一帧没有按时到达，因此接收端重复播放当前帧）。思考是否有方法分别检测这两种卡顿。
- 计算noise的方法采用了相对简单的阈值方法来排除运动区域，但如同freezing一节所述，不同场景下的运动幅度可能差异很大。思考在排除运动区域时如何将这一点考虑在内，使得结果更精确。
- 有研究指出，人眼对视频质量的主观感觉受到上下文的影响。metric数值相同的两帧，可能由于它们各自前后几帧的质量不同，导致人眼对于它们的质量评价不同。思考能否在计算metric时将该因素考虑在内。

**注意：我们再次强调计算复杂度对于视频会议的质量评测是至关重要的。**我们希望每个metric平均每帧的计算时间在0.01s以内（关于我们如何估算代码的运行时间，可参见`utils.py`里的`runtime`装饰器）。在你思考后三个问题时，务必牢记这一点。

